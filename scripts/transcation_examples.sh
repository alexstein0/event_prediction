#python download_and_save_data.py data=ibm_fraud_transaction
#python train_tokenizer.py data=ibm_fraud_transaction
#python tokenize_dataset.py data=ibm_fraud_transaction tokenizer_name=ibm_fraud_transaction_simple
python pretrain_HF.py name=ibm_fraud_transaction wandb=default wandb.tags=['ibm','pretrain'] experiment=ibm_default model.batch_size=32 model.epochs=5 model.train_test_split=.02 model.seq_length=10 model.lr=.00001 impl.print_loss_every_nth_step=1000 impl.save_intermediate_checkpoints=True
python pretrain_HF.py name=ibm_fraud_transaction_exclude_label wandb=default wandb.tags=['ibm','pretrain'] experiment=ibm_default model.batch_size=32 model.epochs=5 model.train_test_split=.02 model.seq_length=10 model.lr=.00001 impl.print_loss_every_nth_step=1000 impl.save_intermediate_checkpoints=True model.percent_mask_all_labels_in_input=0.0 model.percent_mask_labels_in_input=0.0
python pretrain_HF.py name=ibm_fraud_transaction_auc_last wandb=default wandb.tags=['ibm','pretrain'] experiment=ibm_default model.batch_size=32 model.epochs=5 model.train_test_split=.02 model.seq_length=10 model.lr=.00001 impl.print_loss_every_nth_step=1000 impl.save_intermediate_checkpoints=True model.metric_calc_mode=last
python pretrain_HF.py name=ibm_fraud_transaction_exclude_label_auc_last wandb=default wandb.tags=['ibm','pretrain'] experiment=ibm_default model.batch_size=32 model.epochs=5 model.train_test_split=.02 model.seq_length=10 model.lr=.00001 impl.print_loss_every_nth_step=1000 impl.save_intermediate_checkpoints=True model.percent_mask_all_labels_in_input=0.0 model.percent_mask_labels_in_input=0.0 model.metric_calc_mode=last
