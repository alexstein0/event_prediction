# @package _global_

# The other config files this relies on, specified in the format "<folder>: <file>[.yaml]"
defaults:
  - data: ibm_fraud_transaction_small
  - impl: torch-default
  - tokenizer: composite
  - model: gpt2
  - wandb: none
  - _self_
  - override hydra/job_logging: custom

base_dir: outputs
data_dir: data
#processed_data_dir: data
tokenizer_dir: tokenizer

tokenizer_name: ibm_fraud_transaction_simple
preprocess_data_name:

hydra:
  sweep:
    dir: ${base_dir}/${name}/${seed}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  run:
    dir: ${base_dir}/${name}/${seed}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  job:
    chdir: True

seed: # Optional: Set initial seed
name: default # A name for this run [will be used for the outputs folder]

# debug implementation by running every loop just once:
#dryrun: False