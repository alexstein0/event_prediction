# @package _global_

# The other config files this relies on, specified in the format "<folder>: <file>[.yaml]"
defaults:
  - data: ibm_fraud_transaction
  - impl: torch-default
  - tokenizer: simple
  - model: gpt2
#  - model: encoder
  - wandb: none
  - _self_
  - override hydra/job_logging: custom

base_dir: outputs
data_dir: data_raw
tokenizer_dir: tokenizer

tokenizer_name: ${data.name}_${tokenizer.name}
tokenized_data_name:
processed_data_dir: data

model_dir:

save_csv: False
preprocess_only: False

hydra:
  sweep:
    dir: ${base_dir}/${name}/${seed}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  run:
    dir: ${base_dir}/${name}/${seed}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  job:
    chdir: True

seed: # Optional: Set initial seed
name: default # A name for this run [will be used for the outputs folder]

# debug implementation by running every loop just once:
#dryrun: False